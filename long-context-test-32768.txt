### Active Inference Evolution

Active Inference Evolution:

1. **Initial Conceptualization**: Active inference originated as part of the Free Energy Principle (FEP), proposed by neuroscientist Karl Friston around 2006. The FEP suggests that all living systems aim to minimize free energy, a mathematical measure of surprise or uncertainty about the world.

2. **Predictive Coding and Hierarchical Models**: Early developments in active inference were closely tied to predictive coding – the brain constantly making predictions about sensory inputs and updating these based on prediction errors. Hierarchical models were developed to explain how these predictions and errors are processed at various levels of the brain.

3. **Integration of Perception and Action**: Active inference expanded to incorporate not just perceptual processes but also motor control and action. It was understood that the brain's predictions extend to the outcomes of actions, implying we act in ways that fulfill our predictions about the world.

4. **Markov Blankets and Autonomy**: The concept of a Markov blanket – which separates internal states from external states – became crucial for understanding how systems maintain their integrity and autonomy. This helps explain living systems' interactions with their environment while preserving internal order.

5. **Embodiment and Enactivism**: Active inference has been linked to theories of embodiment and enactivism, emphasizing that cognition is deeply rooted in bodily interactions with the world. This perspective underscores how action is integral to perception and learning.

6. **Applications Beyond Neuroscience**: The principles of active inference have been applied in various fields beyond neuroscience, including psychology, philosophy, robotics, and AI, reflecting its utility in explaining complex, adaptive systems across different domains.

7. **Refinement and Diversification**: Recent developments involve refining mathematical formulations and exploring diverse applications such as understanding psychopathologies, modeling social interactions, and developing sophisticated AI systems.

8. **Technological Advances**: Advances in neuroimaging technologies, computational methods, and machine learning have furthered the development of active inference models, allowing for more precise testing of theory predictions and creation of advanced models.

In summary, active inference has evolved from a theoretical construct within the FEP to a comprehensive framework encompassing perception, action, cognition, and their integration within autonomous systems. Its applications have broadened, and it remains a dynamic and growing field of study.


### Agency in Spacetime

Title: Summary of Key Concepts from "Spacetimes with Semantics (I) - Notes on Theory and Formalism" by Mark Burgess

1. **Perspectival Nature of Temporality**: The author argues that the human concept of time is inextricably linked to perspectival thought, emphasizing that perspectival temporality cannot be excluded from semantic representation if it is to remain cognitively plausible. This perspective is developed within a theory of Default Semantics, where temporality reduces to degrees of detachment from the certainty of the present moment (HERE and NOW).

2. **Undefinable Concepts**: Certain fundamental concepts, such as time, space, intelligence, and existence, are deemed undefinable without entering circularities. Self-referential definitions have been employed in physics to cope with these challenges. For instance, time is often defined as what a clock measures.

3. **Observer Semantics**: The author stresses the importance of observer semantics in understanding spacetime, suggesting that traditional models treat spacetime as a separate entity from matter and energy, akin to a measuring apparatus. This perspective leads to problems and contradictions when considering situational differences between observers.

4. **Discrete, Infinite Spacetimes**: Burgess aims to unify descriptions of various fields (physics, chemistry, biology, technology) by exploring discrete, infinite spacetimes using promise theory (autonomous agents). This approach illuminates how observer semantics can be encoded into a description of spacetime.

5. **Mathematical Structures of Spacetime**: The text delves into mathematical structures relevant to understanding spacetime, including:
   - Sets and Topology: Defines neighborhoods, open sets, and concepts like continuity, connectedness, and compactness.
   - Vector Spaces: Discusses vectors as transitions between points, vector spaces' group structure, and properties such as closure, associativity, identity, inverse, and commutativity under addition and scalar multiplication.
   - Group Lattice: Explores the ordered, regular tiling of vectors (lattice structure) in vector spaces, emphasizing homogeneity and isotropy.
   - Naming of Points on a Vector Space: Describes coordinate systems using orthonormal basis vectors and the concept of rank, linear independence, and dimensionality.
   - Tensors, Order, and Rank: Introduces tensors as indexed arrays transforming correctly between different coordinate bases, with order referring to their array structure and rank indicating the number of independent sets composing them.

6. **Distance and Inner Product**: The text explains inner products for vectors (producing a scalar result) and their geometric interpretation as relative lengths or scaled projections. It also discusses the definition of distance in continuous and discrete spaces, suggesting alternative measures like summing bond lengths in a discrete space.

7. **Matrices and Transformations**: The author highlights matrix multiplication's role in representing transformations (e.g., symmetries) between observational states, emphasizing their significance in encoding semantics into spatial models.

8. ** promise theory**: Burgess employs promise theory as a framework to understand autonomous agents and their interactions within spacetimes, enabling the reconstruction of other notions of spacetime from an atomic, local model based on these agents.


In this section of the text, the concept of symmetry and order in Promise Theory is discussed. Here are the key points:

Symmetry in Adjacency Promises:
Adjacency (vector) promise bindings in Promise Theory are analogous to chemical bonds but include semantic types. When agents do not make adjacency promises, they maintain maximal symmetry, which can be referred to as a "gaseous" or "disordered" state by analogy.

Short-Range vs Long-Range Order:
Short-range order refers to the presence of structure in local regions of space, while long-range order implies that this structure extends across larger distances. In Promise Theory, symmetry breaking and the emergence of order can be understood through the lens of autonomous agents' promises.

Short-Range Order:
Short-range order arises when agents make adjacency promises locally but do not impose these preferences on a broader scale. This results in a complex network of relationships without global symmetry, resembling short-range ordered systems like liquids or disordered solids.

Long-Range Order:
Long-range order emerges when agents coordinate their adjacency promises across extended regions. This cooperation leads to the formation of structured patterns that persist over long distances, analogous to crystalline structures with their high symmetry and regularity.

Crystal Lattice Formation:
A collection of autonomous agents can self-organize into a crystal lattice through local promises if these promises are homogeneous over a sufficiently large region. This process is driven by the agents' adherence to promised directional relationships, which results in long-range order and high symmetry.

Homogeneity and Cooperation:
The emergence of long-range order depends on the homogeneity of promise-keeping across agents. Agents must coordinate their behaviors over extended distances, demonstrating cooperative tendencies that allow for the formation of structured spacetime patterns.

Promise Theory's Perspective on Symmetry and Order:
Promise Theory offers a unique perspective on symmetry and order in spacetime by emphasizing the role of autonomous agents' promises in shaping the structure of relationships between elements. This approach allows for the study of both short-range disordered states and long-range ordered structures, providing insights into how complex systems can self-organize through local interactions and cooperation.

In summary, this section explores how symmetry and order arise in Promise Theory through the lens of autonomous agents' adjacency promise bindings. It highlights the distinction between short-range disordered states and long-range ordered structures, demonstrating that complex patterns can emerge from local cooperative behaviors among agents, ultimately leading to high-symmetry crystalline-like configurations in spacetime.


In this section, the author delves into the concept of semantic agencies or "things" within the framework of promise theory. The central idea is that intentional agents differ primarily in their promises, not in their fundamental characteristics. This perspective models reality more accurately than assuming an authoritative design.

The author uses examples to illustrate how simple semantic relationships can be modeled as promises:

1. A pixel (A1) with color RGB: The promised property is the color (RGB).
2. A swimmer (A1) who performs breaststroke: The promised attribute is the type of stroke (breaststroke).
3. A book (A1) that is a work of fiction: The promised characteristic is its genre (fiction).
4. A resistor (A1) with resistance 100Ω and tolerance 5%: The promised properties are the resistance value and tolerance.
5. A girder (A1) made of high-grade steel: The promised attribute is the material it's constructed from (high-grade steel).

These examples demonstrate that agents (A1) are like generic stem cells, whose characteristics are defined solely by the promises they make. In this model, both promising and observing agents are symmetrical elements.

The author then contrasts this promise structure with knowledge relationships in a database of normalized objects:

- In a hypertext web format, relationships between "things" (abstract entities) and their attributes are represented as simple adjacencies. However, navigating these relationships leads to completely different domains (e.g., from pixels to colors).
- Knowledge relationships often act as nexuses of connectivity, connecting various related concepts rather than mere adjacency.

To create a spacetime with both scalar (material) attributes and vector (adjacency) bindings using autonomous agents as the building blocks, the author defines semantic elements or topics:

**Definition 17 (Semantic Element or Topic):** A semantic element or topic T is a tuple consisting of a single autonomous agent Ai and an optional number of scalar material promises {scalarj,...}. 

In summary, this section emphasizes the promise theory approach to modeling semantics by focusing on intentional agents that differ primarily in their promises. It contrasts this model with traditional database representations of knowledge relationships and introduces semantic elements (topics) as a foundation for creating spacetime with both material attributes and adjacency bindings using autonomous agents as building blocks.


In the context of SUq(2) and quantum rotations, operators a and c are central to encoding information about the relative orientations between reference frames. In classical physics, these parameters would correspond to angular coordinates describing the alignment of two reference frames. When promoted to operators acting on a Hilbert space H, they encode the state that defines the orientation between observers A and B's reference frames.

The physical significance of the quantum rotation matrices Rq lies in their ability to extract information about these orientations through expectation values: h|Rq|ψi, where |ψi ∈ H. These expectation values are accompanied by relative uncertainties given by Δij = qh|Rq2 ij|ψi - (h|Rq ij|ψi)2.

A crucial aspect of this framework is the introduction of fuzziness in the alignment procedure: Δij and h|Rq ij|ψi do not vanish simultaneously for a given state |ψi ∈ H. This intrinsic uncertainty prevents A and B from sharply aligning their reference frames beyond a certain level, reflecting the quantum nature of spacetime in this model.

Identifying the Hilbert space H and understanding its representations of operators a and c are essential to fully grasp how these quantum rotations impact the relative orientations between observers' reference frames within the context of quantum gravity. This analysis aims to provide insights into the novel quantum geometrical effects that observers might experience in a quantum spacetime, as discussed in the broader context of this research paper.


Title: Blurring Boundaries: Rethinking Distinctions Between Biology and Technology

Introduction:
This essay explores how recent advancements are challenging traditional distinctions between biology and technology, revealing a spectrum of complementarity. By examining these counterexamples, we can gain new insights into the complex relationships within natural and technological systems.

1. Software/Hardware:
   - Traditional View: Software (instructions) and hardware (physical components) are distinct entities.
   - Counterexample: Physical materials capable of computation and learning, such as physical reservoir computers and computational metamaterials, blur the line between software and hardware.

2. Tape/Machine:
   - Traditional View: A machine needs a tape as a storage medium (Turing machines).
   - Counterexample: Tape-less von Neumann self-replicators demonstrate the possibility of computational systems without traditional tape-based architecture.

3. Digital/Analog:
   - Traditional View: Digital and analog computing are distinct approaches to information processing.
   - Counterexample: Evolved digital circuits exploit electromagnetic properties of their substrate, challenging the distinction between digital and analog computation.

4. Machine/Life form:
   - Traditional View: Machines and living organisms are distinct entities.
   - Counterexample: AI-designed organisms challenge this dichotomy by creating life forms with designed characteristics through artificial intelligence and synthetic biology approaches.

5. Automaton/Free agent:
   - Traditional View: Automatons (deterministic systems) differ from free agents (entities capable of intentional behavior).
   - Counterexample: The intentional stance suggests attributing intentional behavior to complex systems, even without consciousness, challenging the strict separation between automatons and free agents.

6. Brain/Body:
   - Traditional View: The brain and body are distinct entities with separate computational capabilities.
   - Counterexample: Computational metamaterials exhibit computational properties, blurring the line between the brain and the body in terms of computational capabilities.

7. Body/Environment:
   - Traditional View: The body and environment are clearly delineated entities.
   - Counterexample: In multicellular organisms, cells can be seen as both components of the body and the environment for individual cells, challenging the clear distinction between the two.

8. Intelligent/Faking it:
   - Traditional View: Distinguishing true intelligence from simulated intelligence is crucial.
   - Counterexample: AI technologies can pass various Turing tests (verbal, visual, physical), challenging the assumed distinction between true and artificially simulated intelligence.

9. Made/Evolved:
   - Traditional View: Artifacts are products of human design, while living organisms result from natural evolution.
   - Counterexample: Evolutionary algorithms in engineering lead to artifacts designed through an evolutionary process rather than by humans, blurring the distinction between made and evolved.

Conclusion:
The examples provided challenge assumed distinctions between biology and technology, revealing a spectrum of complementarity. By blurring these boundaries, we can embrace a more nuanced understanding of complex relationships in natural and technological systems, fostering interdisciplinary research and innovation.


The text discusses various concepts related to polycomputing, biological systems, evolution, and architecture. Here's a detailed summary and explanation of the key points:

1. Polycomputing Systems in Biology:
Polycomputing refers to biological systems that exhibit multiple computational functions or parallel information processing capabilities. Examples include:
   - Brain: The highly interconnected and distributed architecture of the brain allows for parallel processing, redundancy, and emergent properties, enabling complex cognitive functions like perception, decision-making, and learning.
   - Immune System: This system employs pattern recognition, information processing, and decision-making to mount appropriate immune responses, demonstrating polycomputing capabilities through adaptive and robust behavior.
   - Gene Regulatory Networks (GRNs): GRNs consist of interconnected genes and regulatory elements that can exhibit polycomputing properties by coordinating multiple gene expressions and cellular functions.

2. Evolutionary Processes Repurposing Mechanisms:
Evolution often reuses or modifies existing mechanisms to create new traits or biological processes. Examples include:
   - Gene Duplication: Extra copies of genes provide redundancy, allowing for the evolution of new functions while preserving the original gene's function.
   - Exaptation: A trait or structure evolves for one purpose and later acquires a new function through modification, like feathers in birds, which initially provided insulation but were later exapted for flight.
   - Co-option of Developmental Pathways: Existing developmental pathways are repurposed to generate new structures or traits, such as limbs adapted for different purposes across various animal lineages.

3. Multi-scale Competency Architecture in Biology:
This hierarchical organization of biological systems enables adaptability through interactions and cooperation among different levels of organization (molecular, cellular, tissue, organism). Key features include:
   - Modularity and Functional Redundancy: Modular components with functional redundancy ensure system functionality even when individual parts fail.
   - Emergent Properties and Self-Organization: Collective behaviors arise from interactions at different scales, contributing to adaptability through phenomena like flocking behavior or coordinated movements.
   - Feedback and Regulation: Biological systems employ feedback mechanisms and regulatory networks that enable them to sense and respond to changes in their environment, facilitating adaptability and maintaining homeostasis.

4. Interactions Among Layers in the Multi-scale Competency Architecture:
Different levels of organization within biological systems interact with each other, allowing for coordinated responses and adaptations. Examples include:
   - Molecular-Cellular Interaction: Signaling molecules bind to cell surface receptors, triggering intracellular signaling pathways that lead to changes in gene expression or cellular behavior.
   - Cellular-Tissue Interaction: Collaborative processes among cells maintain tissue structure and function, such as wound healing where cells deposit new extracellular matrix components, migrate into the wound site, and regenerate damaged tissue.

Understanding these concepts helps in appreciating the complexity and adaptability of biological systems, providing insights for developing novel computational approaches inspired by nature.


1. **Polycomputation**: This concept redefines computation as fundamentally observer-driven, implying that the same physical processes can perform multiple computations depending on the perspective of an observer. It challenges traditional notions of computation by emphasizing its dependency on the observer's viewpoint.

2. **Teleophobia**: Coined to describe the fear of overestimating a system's agency when explaining or predicting its behavior, teleophobia underscores the importance of considering the role of the observer in understanding computational processes. It encourages a balanced approach that recognizes potential agency without attributing excessive mechanistic traits to systems.

3. **Synthbiosis**: This term represents the symbiotic relationship between evolved and engineered materials, emphasizing their interdependence and mutual benefit when combined in novel configurations. Synthbiosis highlights the creation of entirely new entities through collaboration between living and artificial components, fostering co-prosperity and thriving together.

4. **Bioprompting**: Drawing parallels to crafting prompts for AI systems, bioprompting involves the ways in which biological systems signal each other to achieve complex outcomes using simple signals. It demonstrates how cells and tissues can be "prompted" to produce intricate results by leveraging their innate competencies and competences.

5. **Competency**: Refers to a system's ability to navigate various spaces, such as anatomical, physiological, metabolic, or transcriptional, depending on how the problem is posed. Competency can often be underestimated if our perspectives are limited, highlighting the importance of diverse viewpoints and comprehensive understanding in evaluating a system's capabilities.

6. **Cognitive Light Cone**: This concept represents the largest goal that a given system can pursue, transcending boundaries between agents (biological, artificial, or extraterrestrial) and categorizing their capacity to achieve different objectives. It provides a framework for comparing and understanding the potential of various entities across domains.

7. **Morphoceuticals** and **Ionoceuticals**: These biomedical interventions utilize anatomical setpoints or target the bioelectric interfaces of cells, respectively, to achieve therapeutic outcomes. By leveraging natural homeostatic mechanisms, morphoceuticals and ionoceuticals offer innovative approaches to manipulating cellular behavior for healing purposes.

8. **Xenobots**: These self-organizing proto-organisms, formed from frog embryonic skin cells, serve as a remarkable platform for exploring the potential of biological innovation. Xenobots transcend their status as mere organisms by encompassing AI design and human scientific collaboration, embodying a multi-scale system that pushes the boundaries of understanding life's plasticity.

9. **Anatomical Compiler**: An anatomical compiler represents a futuristic vision where one can specify desired anatomical outcomes, transforming them into cellular navigation policies. This concept challenges our current comprehension of morphogenesis and reminds us of the vast gulf in understanding biological form-generation processes.

In summary, these interconnected concepts offer a panorama of the ever-evolving scientific landscape. They challenge established frameworks, promote cross-disciplinary exploration, and inspire new ways of understanding computation, life, and healing in an increasingly interconnected world.
