One of the things, from the moment we first met, and one of the things that endeared me
to Hume and what you guys were doing, is how much you mentioned and made an appointment
to say, we are working on establishing the ethical guidelines for how this stuff is going
to be used. And focusing so much on the ethics of it. And that was always such a priority
from the second I met you. And that gave me good vibes. And I was like, all right, well,
let me see what's going on with these people and feel them out. But I knew from the beginning
because of that, because I don't hear a lot of that. I hear, I see a lot of that in headlines
as buzzwords and stuff, but you guys are putting in the work. And it's a very big focus. And
I know you put a lot of effort into making sure that those guidelines are being established.
And that's a very big priority for you guys. And that's been the same, that's been true
from day one, long before you met me, right? Like it was found, the Hume was founded on
that. Am I am I correct in that?
Yeah, I mean, when we created Hume AI, we also created the Hume Initiative, which is a separate
non-profit, like the commitment that anybody using where Hume AI was putting up to the world
would have to comply with the Hume Initiative guidelines, which we're going to be an archive
now been voted upon. Oh, yeah, by like, ethicists, by researchers, by cyber law experts, by
health assets, independent people, that's how we determine what are the supported use
cases and why they've unsupported use cases, the ones that we actually say you cannot pursue
with, you know, and we have defined surveillance as an unsupported use case, you cannot use
our technology to pursue it. And things like manipulation, and we define that in our guidelines.
I'm sure you shouldn't use people's data against that essentially.
Unless, of course, it's like somebody who's misbehaved on a social media platform and
they're bullying somebody, and then you can say like, oh, well, probably should should
use this to make sure there's less bullying.
