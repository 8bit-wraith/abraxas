But the other critique being that we shouldn't use AI to measure our expressions because
the science upon which the AI is built may be flawed, right?
And you guys, you have first hand experience more so than anybody I know in my life can
speak to me about not just abstractly this idea, this concept, but like you've been in
the weeds in the trenches, teaching AI and working on this for years.
This is what you this is where you eat, buddy.
So when someone says and asks the question, should we be using AI to measure our expressions?
And to what end?
I you're the person I want to hear respond to that.
So if you will respond.
I mean, there's all these issues that get conflated in these arguments.
You know, when when they're talking about this, they usually say, you know, AI doesn't
can't detect emotions or AI can't read emotions or emotion AI is pseudoscience.
And all of this is based on the idea that, you know, it goes back to the argument that
expressions are either involuntary readouts of our internal states or they're completely
meaningless. And when you say a measure expressions, you know, then it makes it really clear that
this is an important tool, it's tool for understanding what people are trying to communicate.
Because a lot of what people are saying is not just in their words, but also in the way
that they say things.
There is a relationship between expressions and emotions.
It's more complicated.
They're not entirely, you know, but there's a spectrum from like unconscious, involuntary,
which, you know, expressions are not to completely voluntary, always completely within our
control, which is more like words and expressions are kind of in between.
They're like words and then we can choose whether to express what we're feeling.
So at this, you know, like words, we don't always say what we think.
We don't always think what we say.
Words are really powerful tools for communication.
Nonetheless, the same goes for expression.
Where expressions differ from words is that we have an urge to express ourselves sometimes.
Sometimes we can't help but laugh.
There's some things like blushing that are completely outside of our voluntary control.
Most expressions are within our voluntary control, but they can also be difficult to fake.
You know, it's easier to form an expression that's consistent with what we're feeling than
one that's inconsistent with what we're feeling.
And that's the very thing that makes acting difficult and that makes people who express
their feelings to each other, trust each other more, more than if it was just in text, right?
And what makes me trust somebody when you're with them and you're able to communicate more
successfully when you're with them.
And so it's really, it's a false dichotomy.
Our expressions in voluntary readouts or meaningless, it doesn't make sense.
And the idea that because expressions aren't in voluntary readouts of our emotions, that
we shouldn't have technologies that measure them.
That's like a non sequitur, right?
Because you don't have to believe expressions that direct windows into our emotions to
understand that they're meaningful.
And, you know, it's really, it's taken off in kind of, I think, a harmful way.
I mean, there's many ways in which it's extremely important to be able to measure
expressions with technology and do so in a way that's transparent to humans.
For one thing, technology that measures expressions is going to, it's here, whether
we like it or not, you know, the large language models, any large machine learning model that
processes human data comes up with representations of expressions.
This has been well documented.
There are representations of emotion in GPT three of expression in Dalai and in all of
these large language models, but we just, without having a way of measuring that, we
can't control it.
We can't say this is what you should do when you measure an expression.
This is how you should respond.
These are the good expressions.
These are the bad expressions.
And so we really need this technology to develop, intend them to be able to control
and optimize how technologies treat our emotional behaviors.
And so I think it can do harm to have this argument going around.
