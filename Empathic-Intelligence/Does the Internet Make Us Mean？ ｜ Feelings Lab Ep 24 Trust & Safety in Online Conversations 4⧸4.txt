Do you think the internet has actually made some people be more mean as well?
It sounds like it has in some instances.
There's definitely been effects of how algorithms are upregulating certain aspects of conversation
that people are picking up on actively.
They're saying, well, I'm more likely to get likes if I do this, whether it's conscious
or subconscious.
Right.
There's motivation there.
For Twitter, you say something that's controversial, that gets people a little bit angry, people
will comment on it, people will reply, people will get to the conversation going.
I think, of course, the challenge for responding to that is how do you surface the response
or how do you surface the message that you want to reply with that you hear the anger,
you know why they're angry.
These are the things we're doing about it so that it actually appears in tandem with
the angry comment.
Right.
I don't think that there's really much of a way of doing that right now.
It's probably one of the big challenges.
Yes, no, I do think people that certain emotional tenors do get rewarded by social media, by
the way that online conversations are being moderated, and we need to do something about
that and respond to that.
What?
How do we fix that for me?
Because it is just the worst.
If you could just make it only better, if you could do that, I'd appreciate that.
I mean, yeah, within these sort of algorithms that are sort of moderating these conversations
of the initial level, right now they're being optimized for engagement to some extent, and
they're also being corrected so that they don't too much up-regulate hate speech and
toxic forms of conversation.
There's a lot being done there, but still fundamentally, the algorithm is saying this
is something that people want to see, and I know this because they're liking it, because
they're commenting, and that can easily be exploited because trolls are really good at
making people outraged, and then they like it or comment on it.
It generates a conversation, and suddenly that's jumping to the top of your news feed.
It really needs to be embedded in the algorithm, the sense of why are people paying attention
to this?
Is it just because it's making people angry, in which case that should be appropriately
down-regulated?
You need to understand, you need to predict what the emotional tenor is, how people are
responding emotionally, and I think when you're an organization that's sort of operating
within these mediums and trying to play by their rules, but also be able to mitigate
some of those effects to kind of the same thing.
If you understand why something is going to be up-regulated, you can sort of model that,
and you can embed a response that sort of adjusts the user's emotions, the consumer's emotions
when they see that comment and speaks to those.
