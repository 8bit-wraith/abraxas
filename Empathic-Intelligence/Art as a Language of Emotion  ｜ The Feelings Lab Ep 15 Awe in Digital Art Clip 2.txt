I made a note when you mentioned that you did the experiment with all the different types
of art, right?
So I would assume through that experiment you have some data that sort of tells you what
sort of emotions the different types of work can elicit, right?
Like which kinds of art elicit the most dramatic responses and things like that and so on.
So I'm wondering, do you think you could take that data, right, feed that into a machine
and program it to not just generate imagery or landscapes, but to say generate something
that inspires awe?
What do you think of that, Mike?
Well, I think what's amazing when you look at art and you do that deep dive is that it's
almost every level of the form and depiction of the art conveys really nuanced emotions.
I mean, it down to like the paint stroke, right?
So the things that are kind of spiritual, it's shown in the lighting, it's shown sort
of a halo around things and sort of the haziness and the things that are sort of dreaming
similar, but you know, kind of there's this surreal aspect to it.
There's things that evoke kind of awe and dread and all of these things are kind of,
you know, Rembrandt probably thought about every single paint stroke, not actively thinking
I'm going to convey some specific emotion, but getting a sense of the painting, right?
And feeling it as a human and simulating what the human's response is going to be.
And humans have this amazing simulation capacity where they can take an unfinished product
and sort of imagine the next paint stroke and imagine the next form in it and build
something that's deeply evocative of a really complex set of emotions that they're trying
to convey with this form.
And I think perhaps one thing that AI could use, that AI could learn from that, like learning
from like how you take the minute forms in a computerly rendered scene, right?
And make them a little bit more spiritual or psychedelic or awe inspiring.
And I'm not sure that's there yet, you know, somebody still has to go and sort of draw
the texture.
What's amazing is that once you draw the texture, the AI can just render it across the whole
image, right?
That stuff like that.
I don't know if you want to get that lighting right, but I think there could be ways to
sort of optimize that and really focus on taking aspects that might otherwise be ignored
and making them more intense or pronounced.
That'd be really interesting.
