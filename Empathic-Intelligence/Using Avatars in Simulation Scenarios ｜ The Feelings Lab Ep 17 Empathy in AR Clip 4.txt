But there is still something about the avatar that makes it easier for me to talk to more
receptive to the training and I just would love to know, Arjun, why do you think that
is?
Yeah.
Yeah.
I mean, this is like actually stuff that has been studied by researchers for a couple
of decades now and like Jeremy Balanson is a really, really good friend of mine, is one
of the pioneers in this field.
And even back in the day when we didn't have the technology to create the kind of fidelity
that we need with the avatars, you know, research studies found that people were more willing
to disclose things that they wouldn't do a real human to an avatar.
And there's something fascinating about the psychology of the way we think, like we think
it's a computer and like, you know, when you have a computer and the computer is presenting
a problem to you, your first instinct is, I want to try to beat this.
And the fact that there's no human on the other side, or at least no apparent human
on the other side kind of makes you realize that you're not going to get judged.
It's a safe space.
And if it's a safe space, I can commit errors and I can commit mistakes.
And if you can commit mistakes, it's the best form of learning because we're, as humans,
like I should speak for myself here is like, I do not want to believe the person that says
something's impossible.
I want to go do it myself fail and then say, oh crap, you were right.
And you know, this is giving you that space where you can safely go in hardest of conversations.
You wouldn't know how to approach and you can approach that conversation.
And there's enough stimulus properties in the technology right now to make this feel
like a very real interaction.
And it's all the things that Alan pointed out, which is we've gone to great lengths
to design the AI now where, you know, there's those subtle movements, there's those eyebrow
raises, there's those saccades in the eyes that are kind of looking around.
And our goal is that when somebody interacts with these avatars, it starts to feel real.
And then there's the digital component of this, which makes them feel vulnerable.
And the minute you're vulnerable, you're in there actually learning.
And it's almost, you know, the best form of learning because you're getting immediate
feedback.
You're trying to shape your own behavior in response to the avatar's actions because
clearly you can annoy the avatar.
And it's giving you that visual component that even if you are on the phone, you're
almost now able to visualize what the other person on the other end sounds like, which
we all do every day.
And it's just that the holistic component of, you know, the idea that humans are somehow
more comfortable with digital characters and the idea that it's a safe space.
And the fact that that platform can give you so much measurement, right, which is really
hard to do if you were interacting with a person in real life, you have no measure of
how you're doing.
But here, because you're interacting with a digital character, we're actually capturing
all those signals.
And it's all of the technology that like Alan and the team are working on, you may I, which
is, you know, you look at the facial expressions, you kind of look at how those facial expressions
created a signature for you over the interaction.
You can kind of look at those signatures of different people interacting with the avatars.
And you can almost cluster people saying, Hey, there's a group of like-minded people here.
And that's just from the data.
And when you present the data back to me and you show me, here's a period where you had
a really negative impact on the avatar.
You kind of look at that and go, Oh my God, was I actually doing that?
I did not realize this.
Okay.
Okay.
Okay.
Okay.
Okay.
Okay.
Okay.
Okay.
Okay.
Okay.
Okay.
Okay.
Okay.
Okay.
Okay.
Okay.
Okay.
Okay.
Okay.
Okay.
Okay.
Okay.
