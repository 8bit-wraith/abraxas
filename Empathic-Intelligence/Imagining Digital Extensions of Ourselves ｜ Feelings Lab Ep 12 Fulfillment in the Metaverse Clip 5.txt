Let's have some fun.
We did a little bit of ethics stuff.
I'm going to ask a wild question here.
Greg, you said something fascinating to me in an interview, I think it was in the Verge,
and you had said, at some point in the future, you might be able to create a digital version
of yourself or multiple versions, and they can go out and do stuff.
They can make money for you.
They can make money for your company.
While you're doing something else, that's a whole lot more fun.
I love this idea, and I'm going to let's ignore the countless warnings from Twilight Zone,
Star Trek, and The Simpsons, and I opt in, all right?
I've got three Matt Fortes.
They're out there doing my bidding, and one of them, assigned to my finances,
goes rogue, unbeknownst to me, and steals, I don't know, a quarter of a million dollars.
In a world with autonomous AI, whose fault is that?
Did I do that?
Is it the company through which I got the digital twin?
And again, I'm not holding anybody's feet to the fire.
I'm just curious, what happens when something like this is bound to go down at some point?
What have you guys thought about this?
Do you think about this?
Of course, we think about it, and there are many parallels already in the world today.
There's the cryptocurrency traders, or even in the hedge fund traders,
who've created algorithms that do all of the stuff automatically.
I mean, the simple reality is, our regulatory environment doesn't even cope with the rules
around that, if you will.
Yeah, today, Matt.
So I'm not sure I'm going to give you an intelligent answer,
because the digital man is going to do the alcatraz for the rest of his life.
No idea.
But it's a fun thought experiment.
It helps us personify and make concrete a lot of questions that are important,
even in lieu of digital people, completely.
Like, if you have any AI that's fulfilling things for you, fulfilling tasks for you,
you need to be really careful about what that's optimized for, so that it's good for other people too.
And then there's these ethical questions about how you weigh the trade-offs of what it's doing
for other people versus you, and who should it benefit.
And then there's the question of how it should be optimized for your well-being and
for other people's well-being.
All of these things apply more and more as you give AI more control points in the world.
And digital people have more control points, because they can communicate with people in a way
that you really represent yourself, represents a living being, and that gives them more sway.
And that's one step toward robots.
Eventually, if there was a robot of you, then you'd have to worry about all of the sci-fi issues
that come up in sci-fi.
With the Metaverse, it's interesting, because it's sort of in between.
It gives us a little bit of a playground to experiment with things where the risk isn't
quite so high, because it can't destroy, well, unless it accesses some systems,
that's supposed to, it can't destroy the physical world, and you can keep it away from that.
And so it's nice to be able to live out these scenarios in Metaverse.
I think it will actually be helpful for you.
Thank you.
